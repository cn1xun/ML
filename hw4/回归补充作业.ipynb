{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "编程题：",
   "id": "10695eaf8992f30e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T12:00:49.574323Z",
     "start_time": "2025-08-06T12:00:49.569013Z"
    }
   },
   "source": [
    "# todo 编程题: 在不使用sklearn的情况下，仅使用Numpy，为softmax回归实现带早停的批量梯度下降，将它用于分类任务，例如鸢尾花数据集\n",
    "#  注意：\n",
    "#  1. 要实现l2正则化\n",
    "#  2. 除了数据读取，其他仅使用numpy，包括训练集+验证集分离，以及softmax预测 和 损失计算"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:11:10.019209Z",
     "start_time": "2025-08-06T12:11:09.345586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal width (cm)\", \"petal length (cm)\"]].values\n",
    "y = iris[\"target\"].values\n",
    "\n",
    "# 打乱\n",
    "np.random.seed(42)\n",
    "m = len(X)\n",
    "indices = np.arange(m)\n",
    "np.random.shuffle(indices)\n",
    "X_shuffled = X[indices]\n",
    "y_shuffled = y[indices]\n",
    "\n",
    "# 划分 训练集 测试集\n",
    "split = int(0.8*m)\n",
    "X_train = X_shuffled[:split]\n",
    "y_train = y_shuffled[:split]\n",
    "X_test = X_shuffled[split:]\n",
    "y_test = y_shuffled[split:]\n",
    "\n",
    "# 添加偏执\n",
    "X_train = np.c_[np.ones(X_train.shape[0]), X_train]  # (n_train, d+1)\n",
    "X_test = np.c_[np.ones(X_test.shape[0]), X_test]     # (n_test, d+1)\n",
    "\n",
    "# 类别数\n",
    "n_classes = len(np.unique(y))\n",
    "n_features = X_train.shape[1]  # 包含偏置项\n",
    "\n",
    "# 初始化权重矩阵 W: (n_features, n_classes)\n",
    "W = np.random.randn(n_features, n_classes) * 0.01\n",
    "\n",
    "# 超参数\n",
    "learning_rate = 0.1\n",
    "l2_lambda = 0.01\n",
    "max_epochs = 10000\n",
    "patience = 5  # 早停耐心值\n",
    "tolerance = 1e-5  # 损失变化容忍度\n",
    "\n",
    "# 用于早停的变量\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_W = None\n",
    "\n",
    "def OneHotEncoder(y,num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "# 独热编码 y_train\n",
    "y_train_OHE = OneHotEncoder(y_train, n_classes)\n",
    "y_test_OHE = OneHotEncoder(y_test, n_classes)\n",
    "\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# 代价函数（交叉熵） l2\n",
    "def l2_coss(X,y_OHE,W,l2_lambda):\n",
    "    probs=softmax(X@W)\n",
    "    cross_entopy = -np.sum(y_OHE*np.log(probs + 1e-15))/X.shape[0]\n",
    "    # l2 正则化项\n",
    "    l2_reg = l2_lambda * np.sum(W[1:]**2)\n",
    "    return cross_entopy + l2_reg\n",
    "\n",
    "# 梯度 l2\n",
    "def l2_gradient(X, y_OHE, W, l2_lambda):\n",
    "    probs=softmax(X@W)\n",
    "    grad=(X.T @ (probs - y_OHE))/X.shape[0]\n",
    "    grad[1:, :] += 2 * l2_lambda * W[1:, :]\n",
    "    return grad\n",
    "\n",
    "# 早停\n",
    "for epoch in range(max_epochs):\n",
    "    logit=X_train @ W\n",
    "    probs = softmax(logit)\n",
    "    train_loss = l2_coss(X_train, y_train_OHE, W, l2_lambda)\n",
    "    grad = l2_gradient(X_train, y_train_OHE, W, l2_lambda)\n",
    "    W-= learning_rate * grad\n",
    "    val_loss = l2_coss(X_test, y_test_OHE, W, l2_lambda)\n",
    "    if val_loss < best_loss - tolerance:\n",
    "        best_loss = val_loss\n",
    "        best_W = W.copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    # 打印损失\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    # 判断是否早停\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "def predict(X, W):\n",
    "    return np.argmax(X @ W, axis=1)\n",
    "# 预测\n",
    "y_train_pred = predict(X_train, best_W)\n",
    "y_test_pred = predict(X_test, best_W)\n",
    "print(\"y_test_pred:\",y_test_pred)"
   ],
   "id": "e570eec2e1cc8291",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 1.102275, Val Loss: 0.990831\n",
      "Epoch 1000, Train Loss: 0.380144, Val Loss: 0.416591\n",
      "Epoch 2000, Train Loss: 0.336080, Val Loss: 0.362503\n",
      "Epoch 3000, Train Loss: 0.318111, Val Loss: 0.338302\n",
      "Epoch 4000, Train Loss: 0.309242, Val Loss: 0.325621\n",
      "Epoch 5000, Train Loss: 0.304442, Val Loss: 0.318396\n",
      "Epoch 6000, Train Loss: 0.301696, Val Loss: 0.314046\n",
      "Epoch 7000, Train Loss: 0.300066, Val Loss: 0.311319\n",
      "Early stopping at epoch 7189\n",
      "y_test_pred: [1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1 1 2 2 0 1 1 0 1 2]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T12:11:11.450747Z",
     "start_time": "2025-08-06T12:11:11.435672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 计算准确率\n",
    "train_acc = np.mean(y_train_pred == y_train)\n",
    "test_acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Best Validation Loss: {best_loss:.6f}\")"
   ],
   "id": "2533eed23a3fe290",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9583\n",
      "Test Accuracy: 0.9667\n",
      "Best Validation Loss: 0.310936\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a9a45667086c91d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
