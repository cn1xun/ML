{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b8b340a137572d",
   "metadata": {},
   "source": [
    "## 问答题\n",
    "1. 支持向量机的基本思想是什么？\n",
    "划分一个超平面，用来区分样本\n",
    "2. 什么是支持向量？\n",
    "在划分边界最近的关键样本数据\n",
    "3. 在使用 SVM 时，缩放输入值为什么很重要？\n",
    "SVM计算距离，容易受异常值影响，使用特征缩放（归一化、标准化）\n",
    "4. SVM 分类器在对实例进行分类时能输出置信度分数吗？概率呢？\n",
    "置信度分数：SVM 可以通过 decision_function 输出样本到超平面的符号距离（绝对值越大，置信度越高）。\n",
    "概率：通过设置 probability=True，SVM 可使用 Platt Scaling（逻辑回归校准）输出类别概率（但计算开销较大）。\n",
    "5. 你如何在 LinearSVC、SVC 和 SGDClassifier 之间进行选择？\n",
    "LinearSVC：适合大规模线性分类，支持 L2 正则化。\n",
    "SVC：支持任意核函数（如 RBF），适合非线性分类，计算复杂度高。\n",
    "SGDClassifier：适合超大规模数据（增量学习）\n",
    "6. 假设你已经使用 RBF 核训练了一个 SVM 分类器，但它似乎欠拟合训练集。\n",
    "   你应该增大还是减小 γ（gamma）？C 呢？\n",
    "γ（gamma）：控制核函数的灵敏度。增大 γ 会使核函数更关注邻近样本，模型更复杂（减小可能欠拟合）。\n",
    "C：正则化参数。增大 C 会减少误分类惩罚，允许模型更拟合训练数据（减小可能欠拟合）。\n",
    "调整方向：同时增大 γ（使决策边界更复杂）和增大 C（减少正则化）。\n",
    "7. ε 不敏感模型是什么意思？\n",
    "对于损失函数，只有预测值与真实值偏差超过 ε 时才计算误差\n",
    "8. 使用核技巧有什么意义？\n",
    "核技巧通过将数据隐式映射到高维空间，使原本线性不可分的数据在高维中线性可分，而无需显式计算高维坐标。解决非线性问题同时计算高效\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1dfdea31badc1",
   "metadata": {},
   "source": [
    "## 编程题\n",
    "1. 在葡萄酒数据集上训练SVM分类器，可以使用sklearn.datasets.load_wine()加载它。该数据集包含3个不同种植者生产的178个葡萄酒样本的化学分析：目标是训练一个分类模型，该模型能够根据葡萄酒的化学分析预测种植者。由于SVM分类器是二元分类器，将需要使用“一对全部”对所有三个类进行分类。能达到的精度是多少？\n",
    "\n",
    "   \"一对全部\"可以复习 **8_sklearn做分类.ipynb**里的笔记，里面提到了用二元分类器做多分类问题\n",
    "\n",
    "---\n",
    "\n",
    "2. 提前预习 **10_支持向量机.ipynb** 最新更新的笔记 （把SVM分类用梯度下降实现）； 大概理解笔记后，尝试自己对照笔记 实现用梯度下降实现SVM分类\n",
    "\n",
    "   并把自定义的SVM分类用于 iris data(鸢尾花数据)； 取花瓣长度 和 花瓣宽度特征， 分类 看是不是 分类2的花 （(iris.target == 2)\n",
    "\n",
    "   对比下sklearn自带的SVM分类 和 自定义SVM分类 实现的分类效果\n",
    "\n",
    "---\n",
    "\n",
    "3. 在加州房屋数据集上训练和微调SVM回归器。可以使用原始数据集而不是 在课上使用的调整后的版本，\n",
    "可以使用sklearn.datasets.fetch_california_housing()加载它。目标代表了数十万美元。\n",
    "由于有超过20000个实例，SVM可能会很慢，因此对于超参数调整，应该使用更少的实例（例如2000个）来测试更多的超参数组合。最佳模型的RMSE是多少？\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4210292c3c2ffc48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T05:29:08.692344Z",
     "start_time": "2025-08-12T05:29:02.893732Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_wine = datasets.load_wine()\n",
    "datadf = pd.DataFrame(data_wine.data, columns=data_wine.feature_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(datadf, data_wine['target'],random_state=42)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8662e756dc7d8d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T05:29:09.046850Z",
     "start_time": "2025-08-12T05:29:08.706382Z"
    }
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier  # 一对其余的分类器\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "ovr_clf = make_pipeline(StandardScaler(), OneVsRestClassifier(SVC(random_state=42)))\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "y_pred = ovr_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e8d1e52fd0dca3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T05:29:09.067499Z",
     "start_time": "2025-08-12T05:29:09.055802Z"
    }
   },
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class MyLinearSVC(BaseEstimator):\n",
    "    def __init__(self, C, eta0, n_epochs=1000, random_state=None):\n",
    "        self.C = C\n",
    "        self._alpha = 1 / (2*C)\n",
    "        self.eta0 = eta0\n",
    "        self.n_epochs = n_epochs\n",
    "        self.random_state = random_state\n",
    "\n",
    "    @property\n",
    "\n",
    "    def eta(self):\n",
    "        return self.eta0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m = len(X)\n",
    "        # 随机初始化，可以联系到为什么很多类 会有 random_state这个参数\n",
    "        if self.random_state:\n",
    "            np.random.seed(self.random_state)\n",
    "        w = np.random.randn(X.shape[1], 1)  # n 个 特征权重\n",
    "        b = 0\n",
    "\n",
    "        t = np.array(y, dtype=np.float64).reshape(-1, 1) * 2 - 1  # 把 分类 0 和 分类 1 转成  分类-1 和分类 1\n",
    "        self.Js = []   # 损失值列表\n",
    "\n",
    "        # 训练\n",
    "        for epoch in range(self.n_epochs):\n",
    "            support_vectors_idx = ((X@w + b)*t < 1).ravel()   # 找出支持向量 （损失值不为0的训练集实例， 当前街道内部/分类错误的训练集实例）\n",
    "            X_sv = X[support_vectors_idx]\n",
    "            t_sv = t[support_vectors_idx]\n",
    "\n",
    "            J = (np.sum(w * w) * self._alpha +  np.sum(1- t_sv * (X_sv@w + b))) / m\n",
    "            self.Js.append(J)\n",
    "\n",
    "            w_gradient_vector = (2*self._alpha*w  - X_sv.T @ t_sv) / m\n",
    "            b_derivative = - np.sum(t_sv) / m\n",
    "\n",
    "            w = w - self.eta * w_gradient_vector\n",
    "            b = b - self.eta * b_derivative\n",
    "\n",
    "\n",
    "        self.intercept_ = b\n",
    "        self.coef_ = w\n",
    "        support_vectors_idx = ((X@w + b)*t < 1).ravel()\n",
    "        self.support_vectors_ = X[support_vectors_idx]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return X.dot(self.coef_) + self.intercept_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X) >= 0"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f8361900b72a402a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T05:29:09.130216Z",
     "start_time": "2025-08-12T05:29:09.075133Z"
    }
   },
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "data_iris = datasets.load_iris(as_frame=True)\n",
    "X = data_iris.data[[\"petal width (cm)\", \"petal length (cm)\"]].values\n",
    "y = (data_iris.target == 2).values\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(X, y,random_state=42)\n",
    "my_linearSVC = make_pipeline(StandardScaler(), MyLinearSVC(C=1, eta0 =0.1, n_epochs=500, random_state=42))\n",
    "my_linearSVC.fit(X_train_i, y_train_i)\n",
    "y_test_i\n",
    "y_pred_mlsvc = my_linearSVC.predict(X_test_i)\n",
    "linearSVC = make_pipeline(StandardScaler(),SVC(kernel= 'linear'))\n",
    "linearSVC.fit(X_train_i,y_train_i)\n",
    "y_pred_lsvc = linearSVC.predict(X_test_i)\n",
    "print(\"accuracy_score y_pred_mlsvc:\",accuracy_score(y_pred_mlsvc,y_test_i))\n",
    "print(\"accuracy_score y_pred_lsvc:\",accuracy_score(y_pred_lsvc,y_test_i))\n",
    "print(\"f1_score y_pred_mlsvc:\",f1_score(y_test_i,y_pred_lsvc))\n",
    "print(\"f1_score y_pred_lsvc:\",f1_score(y_test_i,y_pred_lsvc))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score y_pred_mlsvc: 1.0\n",
      "accuracy_score y_pred_lsvc: 1.0\n",
      "f1_score y_pred_mlsvc: 1.0\n",
      "f1_score y_pred_lsvc: 1.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T01:14:22.667398Z",
     "start_time": "2025-08-17T01:13:53.232354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_subset, _, y_subset, _ = train_test_split(X, y, train_size=2000, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_subset_scaled = scaler.fit_transform(X_subset)\n",
    "\n",
    "#\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    SVR(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_subset_scaled, y_subset)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "best_svr = SVR(**grid_search.best_params_)\n",
    "best_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = best_svr.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE\",rmse)"
   ],
   "id": "b51dc049ff9025da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "RMSE 0.5678444859569218\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
